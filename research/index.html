---
layout: default
title: Research
---
<!--<style type="text/css">

 .tab { margin-left: 40px; }

</style>-->
<div class="blurb">
	<!-- <p>The Turtles are still working on this...</p> -->
	<h1>Graph cumulants</h1>
		<p>Over a century ago, Thiele (1889) introduced cumulants, a concept now fundamental to the field of statistics, which has justifiably percolated throughout the scientific community.  In this work, we introduce <i>graph cumulants</i>, their generalization to networks.  This principled hierarchy of network statistics provides a framework to systematically describe and compare networks, naturally including those with additional features, such as directed edges, node attributes, and edge weights.  Moreover, through the lens of the maximum entropy principle, these statistics induce a natural hierarchical family of network models.  These models are immune to the "degeneracy problem", providing a principled prescription for obtaining distributions that are clustered around the properties of the network they intend to model.</p>
		<ul>
			<li style="font-size:24px";>Paper: The Turtles are still working on this...</li>
			<li style="font-size:24px";>Code: The Turtles are still working on this...</li>
		</ul>

	<h1>Graph reduction</h1>
		<p>The deletion of edges (sparsification) and the merging of adjacent vertices (coarsening) are two common methods for reducing a graph.  We analytically unifiy these two operations using a single objective function based on the graph Laplacian pseudoinverse, providing a principled algorithm that simultaneously sparsifies and coarsens a graph while preserving its large-scale structure.</p>
		<ul>
			<li style="font-size:24px";>Videos: 
				<br>
				<a href="https://www.youtube.com/watch?v=xTAPZbQlq3A" target="_blank" style="margin-left:64px; text-decoration:underline; color:blue">NeurIPS 2019</a> (4m14s), <a href="https://www.youtube.com/playlist?list=PLmfiQcz2q6d3sZutLri4ZAIDLqM_4K1p-" target="_blank" style="margin-left:64px; text-decoration:underline; color:blue">graph reduction playlist</a> (1m53s, 0m23s, 0m19s, 0m15s)
			</li>
			<li style="font-size:24px";>Paper: 
				<br>
				<style="font-size:24px"> G Bravo-Hermsdorff and <strong>LM Gunderson</strong>.</style>
				<br>
				"A unifying framework for spectrum-preserving graph sparsification and coarsening"
				<br>
				<i>Advances in Neural Information Processing Systems</i> (2019)
				<a href="https://arxiv.org/abs/1902.09702" target="_blank" style="text-decoration:underline; color:blue">arXiv</a>
			</li>
			<li style="font-size:24px";>Poster: 
				<br>
				<a href="NeurIPS_Poster.pdf" target="_blank" style="margin-left:64px; text-decoration:underline; color:blue">NeurIPS 2019 poster</a>
			</li>
			<li style="font-size:24px";>Code: 
				<br>
				<a href="https://github.com/TheGravLab/A-Unifying-Framework-for-Spectrum-Preserving-Graph-Sparsification-and-Coarsening" target="_blank" style="margin-left:64px; text-decoration:underline; color:blue">GitHub repository</a>
			</li>
		</ul>

</div><!-- /.blurb -->
